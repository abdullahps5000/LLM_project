==========================================
QUICK REFERENCE - Enhanced System
==========================================

1. START SERVICES
   ./scripts/manage.sh start
   ssh abdoulaye@172.20.10.2 'cd ~/LLM_project && ./start_pi_agent.sh'
   ./scripts/manage.sh status

2. SYNC CODE TO PI (after updates)
   ./scripts/sync_to_pi.sh
   ssh abdoulaye@172.20.10.2 'cd ~/LLM_project && ./stop_pi_agent.sh && ./start_pi_agent.sh'

3. RUN INFERENCE (Unified - Recommended)
   source .venv/bin/activate
   python run.py \
     --prompt "Hello!" \
     --max-tokens 50 \
     --model-path /home/abdoulaye/myenv/my_models/Qwen2.5-1.5B-Instruct \
     --urls "http://127.0.0.1:8008,http://172.20.10.2:8008" \
     --pipeline-order "pc,pi" \
     --mem-fraction 0.50 \
     --stream

4. RUN INFERENCE (If plan.json exists)
   python run_inference.py \
     --plan plan.json \
     --prompt "Your prompt" \
     --max-tokens 50 \
     --stream

5. CHECK METRICS
   curl http://127.0.0.1:8008/v1/metrics
   curl http://172.20.10.2:8008/v1/metrics

KEY IMPROVEMENTS:
- KV Cache: 10-100x faster
- Binary Protocol: 2-5x faster
- Progress Tracking: Real-time
- Streaming: See tokens as they generate

See FINAL_USAGE_GUIDE.md for details.
